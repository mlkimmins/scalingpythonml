{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stat.columbia.edu/~rachel/datasets/\n",
    "# https://stat.columbia.edu/~rachel/datasets/csv1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76153b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stat.columbia.edu/~rachel/datasets/nyt0.csv\"\n",
    "#tag::ex_load_1kb[]\n",
    "df = dd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67773fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mayby dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaabebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe by the 'adult' column\n",
    "\n",
    "adult_df = df[df[\"Age\"] >= 19]\n",
    "minors_df = df[df[\"Age\"] < 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6a881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df = adult_df.categorize(columns=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.categorize(\n",
    "    columns=[\"Age\"],\n",
    "    split_every=10\n",
    ")\n",
    "df2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    x=df[\"Age\"],\n",
    "    bins=[0, 18, 24, 34, 44, 54, 64, np.inf]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e19ef",
   "metadata": {},
   "source": [
    "Machine Learning with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a70d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install scikeras>=0.1.8\n",
    "# !pip install tensorflow>=2.3.0\n",
    "# !pip install -U skorch\n",
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "# !pip install pytorch-cpu #not sure if i need to fix this\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25508b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install cloudpickle==2.1.0\n",
    "!pip install dask==2022.05.0\n",
    "!pip install distributed==2022.5.0\n",
    "!pip install lz4==4.0.0\n",
    "!pip install msgpack==1.0.3\n",
    "!pip install toolz==0.11.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ffe9d",
   "metadata": {},
   "source": [
    "setup cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae18ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "# Dask multithreading is only suited for mostly non-Python code (like pandas, numpy, etc.)\n",
    "#tag::threads[]\n",
    "dask.config.set(scheduler='threads')\n",
    "#end::threads[]\n",
    "#tag::process[]\n",
    "dask.config.set(scheduler='processes')\n",
    "#end::process[]\n",
    "#tag::dask_use_forkserver[]\n",
    "dask.config.set({\"multiprocessing.context\": \"forkserver\", \"scheduler\": \"processes\"})\n",
    "#end::dask_use_forkserver[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2fd4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362673f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tag::make_dask_k8s_client[]\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster, make_pod_spec\n",
    "# Use load balancer to make it externally available, for purely internal\n",
    "# the default of \"ClusterIP\" is better.\n",
    "dask.config.set({\"kubernetes.scheduler-service-type\": \"LoadBalancer\"})\n",
    "worker_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='8G', memory_request='8G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "scheduler_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='4G', memory_request='4G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "cluster = KubeCluster(pod_template = worker_template, scheduler_pod_template = scheduler_template)\n",
    "cluster.adapt()    # or create and destroy workers dynamically based on workload\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "#end::make_dask_k8s_client[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f353609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daf43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8bc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8839ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819e01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f48eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# when working with clusters, specify cluster config, n_workers and worker_size\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d86f3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import toolz\n",
    "import dask\n",
    "import dask.array as da\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # optimization algo (eg SGD, Adam)\n",
    "import torch.nn.functional as F # non-linear activation fn (e.g. relu, softmin, softamx, logsigmoid)\n",
    "from torchvision import datasets, transforms # convenience wrapper for datasets and model architectures, common image transformations\n",
    "from torch.utils.data.sampler import SubsetRandomSampler #validation test split\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6336311",
   "metadata": {},
   "source": [
    "1. Extract: get fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7323f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use dask.delayed so that load and transform is lazily done in cluster\n",
    "@dask.delayed\n",
    "def transform(img):\n",
    "    trn = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,),)\n",
    "    ]) #normalize mean / std. given as tuples\n",
    "    #we convert PIL image or numpy.ndarray [0,255] to torch.FloatTensor, (C,H,W) [0.0,1.0]\n",
    "    return trn(img)\n",
    "\n",
    "def transform_nonlazy(img):\n",
    "    trn = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,),)\n",
    "    ]) #normalize mean / std. given as tuples\n",
    "    #we convert PIL image or numpy.ndarray [0,255] to torch.FloatTensor, (C,H,W) [0.0,1.0]\n",
    "    return trn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f90d1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_fashionMNIST_trainset(transform):\n",
    "    trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform = transform)\n",
    "    return trainset\n",
    "\n",
    "def load_fashionMNIST_trainset_nonlazy(transform):\n",
    "    trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform = transform)\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd8f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_fashionMNIST_testset(transform):\n",
    "    testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=False, transform = transform)\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33185015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f856b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/zalandoresearch/fashion-mnist\n",
    "# URL_BASE = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com\"\n",
    "# CHECKSUMS = {\n",
    "#         \"train-images-idx3-ubyte.gz\": \"3aede38d61863908ad78613f6a32ed271626dd12800ba2636569512369268a84\",\n",
    "#         \"train-labels-idx1-ubyte.gz\": \"a04f17134ac03560a47e3764e11b92fc97de4d1bfaf8ba1a3aa29af54cc90845\",\n",
    "#         \"t10k-images-idx3-ubyte.gz\": \"346e55b948d973a97e58d2351dde16a484bd415d4595297633bb08f03db6a073\",\n",
    "#         \"t10k-labels-idx1-ubyte.gz\": \"67da17c76eaffca5446c3361aaab5c3cd6d1c2608764d35dfb1850b086bf8dd5\",\n",
    "#     }\n",
    "\n",
    "# prefix = \"train\" #if split == train, else \"t10k\"\n",
    "# images_file = f\"{prefix}-images-idx3-ubyte.gz\"\n",
    "# labels_file = f\"{prefix}-labels-idx1-ubyte.gz\"\n",
    "# # http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44782e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960fbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24700593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dask.delayed\n",
    "def load(path, fs=__builtins__):\n",
    "    with fs.open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img\n",
    "\n",
    "# @dask.delayed\n",
    "# def load_csv(path):\n",
    "#     import pandas as pd\n",
    "#     return pd.read_csv(path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded625f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objs = [load_csv(x) for x in glob.glob(\"fashion_mnist/dataset/fashion-mnist_train.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = load_fashionMNIST_trainset(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dask.compute(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = x[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b812c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = x[0].train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(4, 20/4, idx+1, xticks=[], yticks=[])\n",
    "    ax. imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(labels[idx].item())\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4fdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13abea41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jn/54vtqbx5231b0w09shgckwv80000gn/T/ipykernel_38116/842884009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# train_loader = td.DataLoader(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'objs' is not defined"
     ]
    }
   ],
   "source": [
    "trainset_len = 6000 #cheating a bit - we already know length\n",
    "indices = list(range(trainset_len))\n",
    "split = int(np.floor(0.2 * trainset_len))\n",
    "batch_size = 64\n",
    "num_workers = 4 #would get it from distributed client\n",
    "train_sampler = SubsetRandomSampler(indices[:split])\n",
    "\n",
    "# import torch.utils.data as td\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    objs, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers\n",
    ")\n",
    "# train_loader = td.DataLoader(\n",
    "#     objs, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c67ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f393911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors = [transform(x) for x in objs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = [dask.delayed(torch.stack)(batch)\n",
    "#            for batch in toolz.partition_all(10, tensors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a814cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f835b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images are 28x28 2d tensors. flatten to 1d vector\n",
    "# 28*28 = 784 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d547bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture in this class.\n",
    "# Pytorch's nn.module that we inherit for the architecture definition\n",
    "# we use 3 hidden layers, 1 output layer\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    import torch.nn as nn\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc1 = nn.Linear(784, 256) # linear transformation from 784 input -> 256 output for first hidden layer\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "#         define 20% dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x))) # we use RELU activation function for each hidden layer\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "#         dont use dropout on output layer\n",
    "        x = F.log_softmax(self.fc3(x), dim=1) #final output layer use softmax for log-probabilities\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "#loss fn\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "valid_loss_min = np.Inf #use high val to ensure weights are updated first time\n",
    "epochs = 20 #short epoch for now\n",
    "steps = 0\n",
    "model.train() #model prep prior to training\n",
    "train_losses, valid_losses = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97df56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def train(images, labels):\n",
    "    optimizer.zero_grad()\n",
    "    log_ps = model(images)\n",
    "    loss = criterion(log_ps, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()*images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def fake_train(x):\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8f80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a4d0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors_01 = client.submit(load_fashionMNIST_trainset(transform))\n",
    "tensors = []\n",
    "tensor = client.submit(load_fashionMNIST_trainset(transform))\n",
    "tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1155ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = client.gather(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49c74f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = xx[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41ea6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:03:21,539 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       apply-687810a0-1f94-4a8d-a038-78c95b18a69f\n",
      "Function:  execute_task\n",
      "args:      ((<function apply at 0x7f83feb93ca0>, Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: /Users/mk/.pytorch/F_MNIST_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: <function transform at 0x7f84049de160>, (<class 'tuple'>, []), (<class 'dict'>, [])))\n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"\\'FashionMNIST\\' object is not callable\")'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'FashionMNIST' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jn/54vtqbx5231b0w09shgckwv80000gn/T/ipykernel_38116/1238842062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3002\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3004\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3005\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   2179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'FashionMNIST' object is not callable"
     ]
    }
   ],
   "source": [
    "xxx.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a333c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:02:26,883 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       stack-f5ad50c8f8d53abb4b73b81319ff5201\n",
      "Function:  execute_task\n",
      "args:      ((<built-in method stack of type object at 0x11f504770>, (Delayed('apply-687810a0-1f94-4a8d-a038-78c95b18a69f'),)))\n",
      "kwargs:    {}\n",
      "Exception: 'TypeError(\"stack(): argument \\'tensors\\' (position 1) must be tuple of Tensors, not Delayed\")'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batches = []\n",
    "for b in toolz.partition_all(10, tensors):\n",
    "    print(b.result())\n",
    "#     batch = client.submit(torch.stack, b)\n",
    "#     batches.append(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a360a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c3be9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function transform at 0x7f803fa2c040>: it's not the same object as __main__.transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jn/54vtqbx5231b0w09shgckwv80000gn/T/ipykernel_38116/2474838880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# #     print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mset_spawning_popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mForkingPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function transform at 0x7f803fa2c040>: it's not the same object as __main__.transform"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "whole_dataset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=False, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    whole_dataset, sampler=train_sampler, batch_size=batch_size, num_workers=num_workers\n",
    ")\n",
    "\n",
    "for image, labels in train_loader:\n",
    "    pass\n",
    "# #     print(image)\n",
    "# #     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83260300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c773330",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    valid_loss = 0\n",
    "    running_loss = 0\n",
    "    #train model\n",
    "#     for images, labels in trainloader:\n",
    "    for images, labels in objs:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "    \n",
    "#     for images, labels in validloader:\n",
    "#         log_ps = model(images)\n",
    "#         loss = criterion(log_ps, labels)\n",
    "#         valid_loss += loss.item()*images.size(0)\n",
    "\n",
    "# running_loss =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38774daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b84f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e01396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9f5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80a7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole_trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform = transform)\n",
    "# trainset_len = 6000 #cheating a bit - we already know length\n",
    "# indices = list(range(trainset_len))\n",
    "# split = int(np.floor(0.2 * trainset_len))\n",
    "# batch_size = 64\n",
    "# num_workers = 4 #would get it from distributed client\n",
    "# sampler = SubsetRandomSampler(indices[:split])\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     whole_trainset, sampler=sampler, batch_size=batch_size, num_workers=num_workers\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8a789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loader = load_fashionMNIST_trainset(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78230a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded = dask.compute(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7edc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00c971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lazy load\n",
    "# note we aren't using torch.utils.DataLoader\n",
    "# whole_trainset = load_fashionMNIST_trainset(transform)\n",
    "# whole_trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd438ba",
   "metadata": {},
   "source": [
    "non-dask way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9188556",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dask_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,),)\n",
    "    ])\n",
    "whole_trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data', download=True, train=True, transform = non_dask_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffe57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_len = 6000 #cheating a bit - we already know length\n",
    "indices = list(range(trainset_len))\n",
    "split = int(np.floor(0.2 * trainset_len))\n",
    "batch_size = 64\n",
    "num_workers = 4 #would get it from distributed client\n",
    "validation_sampler = SubsetRandomSampler(indices[:split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72627d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    whole_trainset, sampler=validation_sampler, batch_size=batch_size, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(4, 20/4, idx+1, xticks=[], yticks=[])\n",
    "    ax. imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(labels[idx].item())\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74edc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c77b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244a007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd42d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045e80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b1fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21002a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae32c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675eec70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb9bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8c1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfecd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0c150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3372b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316322c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ecfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7497b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e5ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
